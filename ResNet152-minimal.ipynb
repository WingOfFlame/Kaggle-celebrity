{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "efaeee83-6017-4747-82ae-51e5dfc2c796",
    "_uuid": "e67cdd3c4e9f78c391845a3390d9c09a8fd24814",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# always essential \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# image processing\n",
    "from PIL import Image, ImageOps\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#import imgaug as ia\n",
    "#from imgaug import augmenters as iaa\n",
    "\n",
    "# CNN model\n",
    "from keras.optimizers import RMSprop, SGD\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
    "import resnet\n",
    "import tensorflow as tf\n",
    "\n",
    "# system/util\n",
    "import glob\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d7d07f8a-22ea-4b10-ad23-b73a94e25a10",
    "_uuid": "956a9b01c15a09004580b4021448fb88db33c935",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(os.listdir(\"../input/cs4780_sp18_bonus\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Modify your path accordingly!!!__\n",
    "\n",
    "My path is for Kaggle Kernel\n",
    "\n",
    "Also I will upload these npy to a public Kaggle Datasource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "475ac7f9-3025-4dfa-b7db-1a4aa7977a96",
    "_uuid": "2f418cba09060875c80f7029c260684c6a8e7946",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.load('../input/cs4780_sp18_bonus/X_train.npy')\n",
    "Y_train = np.load('../input/cs4780_sp18_bonus/Y_train.npy')\n",
    "# for prediction\n",
    "X_test = np.load('../input/cs4780_sp18_bonus/X_test.npy')\n",
    "# for submission\n",
    "celeberty_names = np.load('../input/cs4780_sp18_bonus/names.npy')\n",
    "file_names = np.load('../input/cs4780_sp18_bonus/test_files.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "930693ef-3b53-429d-8a69-562aba34eb2d",
    "_uuid": "5d3bb04c464be93b1c08eccd0dbcbfb27389bf84"
   },
   "source": [
    "# Data Procesing\n",
    "\n",
    "### Augmentation + Normalization + Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a9cc0e71-6bd3-41c8-9c02-d4147979dad7",
    "_uuid": "3e747fbf8ffda2e4d0953ad1263bb57acd851305",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.15,\n",
    "        height_shift_range=0.15,\n",
    "        brightness_range=(0.8,1.2),\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.1,\n",
    "        channel_shift_range=0.2,\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False,\n",
    "        rescale=None,\n",
    "        preprocessing_function=None,\n",
    "        data_format=\"channels_last\",\n",
    "\n",
    "        featurewise_center=True,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=True,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "    \n",
    "        validation_split=0.2\n",
    ")\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet.ResNet152(weights=None,input_shape=(300,300,3),classes=98)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d9ed0508-f53c-4581-8c2c-12c3a33e2afe",
    "_uuid": "2feac0951ebdd7f050e948a1f0e7ef6a48fe3ca9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "decay = 0.0\n",
    "momentum=0.9\n",
    "rho=0.9\n",
    "\n",
    "epochs = 32 # Turn epochs to 30 to get 0.9967 accuracy\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = RMSprop(lr=lr, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "sgd = SGD(lr=1e-2, decay=1e-6, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(optimizer=rms, \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leraning rate reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.2, \n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d46f978a-cd16-46ed-9c23-eb9c7d192abe",
    "_uuid": "3bdd7287d526ec1c7c7dfec4120e771e3f289186",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(generator=datagen.flow(X_train, Y_train, subset = \"training\"),\n",
    "                              validation_data = datagen.flow(X_train, Y_train, subset = \"validation\"),\n",
    "                              epochs = epochs, \n",
    "                              verbose = 2, \n",
    "                              steps_per_epoch=X_train.shape[0] // batch_size,\n",
    "                              callbacks=[learning_rate_reduction]\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(X_test)\n",
    "\n",
    "# select the indix with the maximum probability\n",
    "results = np.argmax(results,axis = 1)\n",
    "results = [celeberty_names[i] for i in results]\n",
    "\n",
    "results = pd.Series(results,name=\"celebrity_name\")\n",
    "submission = pd.concat([pd.Series(file_names,name = \"image_label\"),results],axis = 1)\n",
    "\n",
    "submission.to_csv(\"celeberty_resnet_152.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
